{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System Using Item-Item Collaborative Filtering vs Content-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Sampled Rating Dataset\n",
    "\n",
    "The full MovieLens ratings dataset is quite large. For practical experimentation, we need to load the sampled dataset that we made before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings():\n",
    "    \"\"\"Load ratings dataset, either from filtered file if exists or process the full dataset\"\"\"\n",
    "    if os.path.exists(\"filtered_ratings.csv\"):\n",
    "        print(f\"Loading pre-filtered ratings from filtered_ratings.csv\")\n",
    "        return pd.read_csv(\"filtered_ratings.csv\")\n",
    "    else:\n",
    "        print(\"Filtered ratings file not found. Please run the data processing steps first.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Normalization for Item-Item Collaborative Filtering\n",
    "\n",
    "Before implementing our recommendation algorithm, we need to transform the raw data into a suitable format. Good data preparation is crucial for the accuracy of our recommendations.\n",
    "\n",
    "In this section, we'll:\n",
    "1. Load our saved filtered ratings\n",
    "2. Clean the movies dataset\n",
    "3. Keep only the necessary columns\n",
    "4. Normalize the ratings data\n",
    "5. Prepare data structures for item-item collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Initializing the Data\n",
    "\n",
    "First, we load our preprocessed data. This gives us a clean starting point with a manageable dataset size while preserving the important characteristics of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the filtered ratings dataset\n",
    "ratings = load_ratings()\n",
    "print(f\"Loaded {len(ratings)} ratings from {ratings['userId'].nunique()} users on {ratings['movieId'].nunique()} movies\")\n",
    "\n",
    "# Let's also load the cleaned movies data\n",
    "movies = pd.read_csv('movies_tuned.csv', low_memory=False)\n",
    "print(f\"Loaded {len(movies)} movies from metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: Movie Metadata\n",
    "\n",
    "The movie metadata contains rich information but needs cleaning. We'll focus on extracting the essential information for our recommendation system:\n",
    "\n",
    "1. Movie ID and title for identification\n",
    "2. Genre information for content-based features\n",
    "\n",
    "We'll parse the genre information from its JSON format and convert IDs to match our ratings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the movies dataset\n",
    "# First, let's check what columns are available\n",
    "print(\"Movies dataset columns:\")\n",
    "print(movies.columns.tolist())\n",
    "\n",
    "# For item-item collaborative filtering, we only need minimal movie information\n",
    "# Keep only id, title, and maybe genres\n",
    "movies_cleaned = movies[['id', 'title', 'genres']].copy()\n",
    "\n",
    "# Convert id to int to match with movieId in ratings\n",
    "# Some IDs might not be convertible to int, so we'll handle exceptions\n",
    "def safe_convert_id(x):\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "movies_cleaned['id'] = movies_cleaned['id'].apply(safe_convert_id)\n",
    "movies_cleaned = movies_cleaned.dropna(subset=['id'])\n",
    "movies_cleaned['id'] = movies_cleaned['id'].astype(int)\n",
    "\n",
    "# Rename 'id' to 'movieId' to match ratings dataframe\n",
    "movies_cleaned = movies_cleaned.rename(columns={'id': 'movieId'})\n",
    "\n",
    "# Parse genres from JSON string format if necessary\n",
    "import json\n",
    "import ast\n",
    "\n",
    "def extract_genres(genres_str):\n",
    "    try:\n",
    "        if isinstance(genres_str, str):\n",
    "            # Try to parse as JSON first\n",
    "            try:\n",
    "                genres_list = json.loads(genres_str.replace(\"'\", '\"'))\n",
    "            except:\n",
    "                # If that fails, try ast.literal_eval\n",
    "                try:\n",
    "                    genres_list = ast.literal_eval(genres_str)\n",
    "                except:\n",
    "                    return []\n",
    "                \n",
    "            # Extract genre names\n",
    "            return [g['name'] for g in genres_list if 'name' in g]\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "movies_cleaned['genres_list'] = movies_cleaned['genres'].apply(extract_genres)\n",
    "movies_cleaned['genres_str'] = movies_cleaned['genres_list'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Drop the original genres column and the intermediate list\n",
    "movies_cleaned = movies_cleaned.drop(columns=['genres', 'genres_list'])\n",
    "\n",
    "# Display the cleaned movies data\n",
    "print(f\"\\nCleaned movies data: {len(movies_cleaned)} entries\")\n",
    "movies_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: Ratings\n",
    "\n",
    "For our collaborative filtering approach, we need to ensure the ratings data is in the correct format and properly linked to our movie metadata. This includes:\n",
    "\n",
    "1. Keeping only essential columns (user ID, movie ID, rating)\n",
    "2. Ensuring consistent data types\n",
    "3. Joining with the movies data to ensure we only keep ratings for movies we have information for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the ratings dataset\n",
    "# For collaborative filtering, we only need userId, movieId, and rating\n",
    "print(\"Ratings dataset columns:\")\n",
    "print(ratings.columns.tolist())\n",
    "\n",
    "ratings_cleaned = ratings[['userId', 'movieId', 'rating']].copy()\n",
    "\n",
    "# Ensure all IDs are integers\n",
    "ratings_cleaned['userId'] = ratings_cleaned['userId'].astype(int)\n",
    "ratings_cleaned['movieId'] = ratings_cleaned['movieId'].astype(int)\n",
    "\n",
    "# Merge with movies data to ensure we only keep ratings for movies we have information for\n",
    "ratings_with_info = ratings_cleaned.merge(movies_cleaned[['movieId']], on='movieId', how='inner')\n",
    "\n",
    "print(f\"\\nCleaned ratings data: {len(ratings_with_info)} entries\")\n",
    "print(f\"Number of unique users: {ratings_with_info['userId'].nunique()}\")\n",
    "print(f\"Number of unique movies: {ratings_with_info['movieId'].nunique()}\")\n",
    "\n",
    "# Display sample of cleaned ratings\n",
    "ratings_with_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Normalization\n",
    "\n",
    "Different users have different rating behaviors - some are generous with high ratings while others tend to rate more critically. We normalize ratings by subtracting each user's mean rating to account for these individual differences. This normalization is a crucial step for improving recommendation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the ratings by user mean\n",
    "# This helps account for different rating scales used by different users\n",
    "\n",
    "# Calculate the mean rating for each user\n",
    "user_mean_ratings = ratings_with_info.groupby('userId')['rating'].mean()\n",
    "\n",
    "# Create function to normalize ratings\n",
    "def normalize_rating(row):\n",
    "    return row['rating'] - user_mean_ratings[row['userId']]\n",
    "\n",
    "# Add normalized ratings\n",
    "ratings_with_info['rating_norm'] = ratings_with_info.apply(normalize_rating, axis=1)\n",
    "\n",
    "# Display sample to see both original and normalized ratings\n",
    "print(\"Sample ratings with normalization:\")\n",
    "sample_users = ratings_with_info['userId'].unique()[:3]\n",
    "sample_data = ratings_with_info[ratings_with_info['userId'].isin(sample_users)].head(10)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the User-Item Ratings Matrix\n",
    "\n",
    "The foundation of collaborative filtering is a user-item matrix where rows represent users, columns represent movies, and values are the normalized ratings. This matrix representation enables efficient similarity calculations between items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-item ratings matrix (needed for item-item collaborative filtering)\n",
    "# This will be a sparse matrix where rows are users and columns are items/movies\n",
    "\n",
    "# Create the sparse matrix using pivot_table\n",
    "ratings_matrix = ratings_with_info.pivot_table(\n",
    "    index='userId', \n",
    "    columns='movieId', \n",
    "    values='rating_norm'  # Using normalized ratings\n",
    ")\n",
    "\n",
    "print(f\"Created ratings matrix with shape: {ratings_matrix.shape}\")\n",
    "\n",
    "# Let's see a small sample of the matrix\n",
    "print(\"\\nSample of the user-item ratings matrix:\")\n",
    "ratings_matrix.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Clean Datasets\n",
    "\n",
    "After all our preprocessing work, we save the cleaned datasets to disk. This preserves our progress and allows us to quickly reload the processed data in future sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed datasets\n",
    "# This allows us to skip the preprocessing steps in the future\n",
    "\n",
    "# Save cleaned movies data\n",
    "movies_cleaned.to_csv('../movies_data/movies_cleaned.csv', index=False)\n",
    "\n",
    "# Save cleaned and normalized ratings\n",
    "ratings_with_info.to_csv('../movies_data/ratings_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Preprocessed data saved to disk.\")\n",
    "print(f\"- Movies data: {len(movies_cleaned)} movies saved\")\n",
    "print(f\"- Ratings data: {len(ratings_with_info)} ratings saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Item Collaborative Filtering using Pearson Correlation\n",
    "\n",
    "We now implement the core of our recommendation system using item-item collaborative filtering. This approach is based on the idea that similar items tend to be rated similarly by users.\n",
    "\n",
    "Unlike user-based approaches, item-based collaborative filtering builds a model of item similarities that's more stable over time, since item properties change less frequently than user preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Similarity Function\n",
    "\n",
    "We'll use the Pearson correlation coefficient to measure similarity between items. This metric captures linear relationships between item ratings while accounting for differences in mean and variance, making it robust to different user rating scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate item-item similarity using Pearson correlation coefficient\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# Transpose the ratings matrix so columns are users and rows are items\n",
    "# This makes it easier to compute item-item similarity\n",
    "item_user_matrix = ratings_matrix.T\n",
    "\n",
    "print(f\"Item-user matrix shape: {item_user_matrix.shape}\")\n",
    "\n",
    "# Function to compute Pearson correlation between two items\n",
    "def compute_pearson_similarity(item1, item2):\n",
    "    # Get ratings for both items, only considering users who rated both\n",
    "    common_users = item1.notna() & item2.notna()\n",
    "    if common_users.sum() < 5:  # Need at least 5 common ratings for reliability\n",
    "        return 0\n",
    "        \n",
    "    item1_ratings = item1[common_users]\n",
    "    item2_ratings = item2[common_users]\n",
    "    \n",
    "    if len(item1_ratings) == 0 or np.std(item1_ratings) == 0 or np.std(item2_ratings) == 0:\n",
    "        return 0\n",
    "        \n",
    "    try:\n",
    "        corr, _ = pearsonr(item1_ratings, item2_ratings)\n",
    "        return corr if not np.isnan(corr) else 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Scope of Analysis\n",
    "\n",
    "Computing similarities between all possible movie pairs would be computationally prohibitive. We focus on the most frequently rated movies for two reasons:\n",
    "\n",
    "1. They have more data points for reliable similarity calculations\n",
    "2. They're likely to be more relevant for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Since computing the full similarity matrix might be computationally expensive,\n",
    "#  we'll limit our analysis to the top N most-rated movies\n",
    "num_top_movies = 3000\n",
    "\n",
    "# Get the most rated movies\n",
    "movie_ratings_count = ratings_with_info['movieId'].value_counts()\n",
    "top_rated_movies = movie_ratings_count.nlargest(num_top_movies).index.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Item-Item Similarity Matrix\n",
    "\n",
    "This is the most computationally intensive part of our process. We'll calculate pairwise similarity between movies using the Pearson correlation of their ratings. We only store meaningful correlations (above a threshold of 0.2) to save memory and improve efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(f\"Computing similarity for the top {num_top_movies} most rated movies...\")\n",
    "\n",
    "# # Create a dictionary to store similar items for each movie\n",
    "# item_similarity = {}\n",
    "\n",
    "# # For each movie in our top list, find its similarity with all other movies\n",
    "# for i, movie_id in enumerate(top_rated_movies):\n",
    "#     if i % 100 == 0:\n",
    "#         print(f\"Processing movie {i}/{len(top_rated_movies)}\")\n",
    "        \n",
    "#     # Skip if movie is not in our item_user_matrix\n",
    "#     if movie_id not in item_user_matrix.index:\n",
    "#         continue\n",
    "        \n",
    "#     item1 = item_user_matrix.loc[movie_id]\n",
    "#     item_similarity[movie_id] = {}\n",
    "    \n",
    "#     for other_movie_id in top_rated_movies:\n",
    "#         if movie_id == other_movie_id or other_movie_id not in item_user_matrix.index:\n",
    "#             continue\n",
    "            \n",
    "#         item2 = item_user_matrix.loc[other_movie_id]\n",
    "#         sim = compute_pearson_similarity(item1, item2)\n",
    "        \n",
    "#         # Only keep significant similarities\n",
    "#         if abs(sim) > 0.2:  # Threshold for meaningful correlation\n",
    "#             item_similarity[movie_id][other_movie_id] = sim\n",
    "\n",
    "# print(\"Similarity computation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Precomputed Similarities\n",
    "\n",
    "Since computing the similarity matrix is time-consuming, we can save it to disk and reload it in future sessions. This significantly speeds up experimentation with different recommendation algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load item similarity matrix from disk\n",
    "\n",
    "try:\n",
    "    # Attempt to load the precomputed similarity matrix\n",
    "    with open('../movies_data/item_similarity_3000.pkl', 'rb') as f:\n",
    "        item_similarity = pickle.load(f)\n",
    "    \n",
    "    print(f\"Item similarity matrix loaded with {len(item_similarity)} items\")\n",
    "    print(f\"First 5 items: {list(item_similarity.keys())[:5]}\")\n",
    "except FileNotFoundError:\n",
    "    # If the file doesn't exist, initialize an empty dictionary\n",
    "    print(\"Item similarity file not found.\")\n",
    "    print(\"Please run the similarity computation code first or use the commented out code in cell 16.\")\n",
    "    item_similarity = {}\n",
    "except Exception as e:\n",
    "    print(f\"Error loading item similarity matrix: {e}\")\n",
    "    item_similarity = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Item Similarities\n",
    "\n",
    "Let's examine how our similarity calculations work in practice by looking at examples of similar movies. This helps verify that our approach is capturing meaningful relationships between items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the top N similar items for a given item\n",
    "def get_similar_movies(movie_id, n=10):\n",
    "    if movie_id not in item_similarity:\n",
    "        return []\n",
    "        \n",
    "    # Sort similar items by similarity score (descending)\n",
    "    similar_items = sorted(item_similarity[movie_id].items(), key=lambda x: x[1], reverse=True)\n",
    "    return similar_items[:n]\n",
    "\n",
    "# Let's look at some examples\n",
    "# First, choose a few popular movies from our dataset\n",
    "# Create movie counts dataframe with clear column names\n",
    "movie_counts_df = ratings_with_info['movieId'].value_counts().reset_index()\n",
    "movie_counts_df.columns = ['movieId', 'count']\n",
    "\n",
    "# Merge with movies_cleaned to get titles of popular movies\n",
    "popular_movies = movies_cleaned.merge(\n",
    "    movie_counts_df,\n",
    "    on='movieId'\n",
    ").sort_values('count', ascending=False).head(5)[['movieId', 'title']]\n",
    "\n",
    "print(\"Some popular movies in our dataset:\")\n",
    "for _, row in popular_movies.iterrows():\n",
    "    print(f\"Movie ID: {row['movieId']}, Title: {row['title']}\")\n",
    "    \n",
    "    # Get similar movies\n",
    "    similar = get_similar_movies(row['movieId'], 5)\n",
    "    \n",
    "    if similar:\n",
    "        print(\"Similar movies:\")\n",
    "        for movie_id, similarity in similar:\n",
    "            # Get movie title\n",
    "            title = movies_cleaned[movies_cleaned['movieId'] == movie_id]['title'].values\n",
    "            if len(title) > 0:\n",
    "                title = title[0]\n",
    "            else:\n",
    "                title = f\"Movie {movie_id}\"\n",
    "            print(f\"  - {title} (similarity: {similarity:.3f})\")\n",
    "    else:\n",
    "        print(\"  No similar movies found\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Rating Prediction Algorithm\n",
    "\n",
    "The core prediction function uses weighted averaging of similar items to predict a user's rating for an item they haven't rated yet. The weights are based on the similarity scores, giving more influence to highly similar items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict a user's rating for an item\n",
    "def predict_rating(user_id, movie_id, k=10):\n",
    "    \"\"\"Predict a user's rating for a movie using item-based collaborative filtering\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): User ID\n",
    "        movie_id (int): Movie ID\n",
    "        k (int): Number of similar items to consider\n",
    "        \n",
    "    Returns:\n",
    "        float: Predicted rating\n",
    "    \"\"\"\n",
    "    # If user or movie not in our data, return None\n",
    "    if user_id not in ratings_matrix.index or movie_id not in item_similarity:\n",
    "        return None\n",
    "    \n",
    "    # Get the user's ratings\n",
    "    user_ratings = ratings_matrix.loc[user_id]\n",
    "    \n",
    "    # Get similar movies that the user has rated\n",
    "    if movie_id not in item_similarity:\n",
    "        return None\n",
    "        \n",
    "    similarities = item_similarity[movie_id]\n",
    "    rated_similar = []\n",
    "    \n",
    "    for similar_id, sim in similarities.items():\n",
    "        if similar_id in user_ratings and not np.isnan(user_ratings[similar_id]):\n",
    "            rated_similar.append((similar_id, sim, user_ratings[similar_id]))\n",
    "    \n",
    "    if not rated_similar:\n",
    "        return None\n",
    "    \n",
    "    # Sort by similarity and take top k\n",
    "    rated_similar.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    rated_similar = rated_similar[:k]\n",
    "    \n",
    "    # Calculate weighted average rating\n",
    "    numerator = sum(sim * rating for _, sim, rating in rated_similar)\n",
    "    denominator = sum(abs(sim) for _, sim, _ in rated_similar)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return None\n",
    "        \n",
    "    # Get the user's average rating to add back (since we used normalized ratings)\n",
    "    user_mean = user_mean_ratings[user_id]\n",
    "    \n",
    "    # Return predicted rating\n",
    "    predicted = numerator / denominator + user_mean\n",
    "    return min(max(predicted, 0.5), 5.0)  # Clip to valid rating range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Movie Recommendation Function\n",
    "\n",
    "Now we can create a function that generates personalized movie recommendations for a user. The function identifies movies the user hasn't seen yet, predicts their ratings, and returns the top recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate movie recommendations for a user\n",
    "def recommend_movies(user_id, n=10, min_ratings=5):\n",
    "    \"\"\"Generate movie recommendations for a user\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): User ID\n",
    "        n (int): Number of recommendations to generate\n",
    "        min_ratings (int): Minimum number of ratings a movie should have\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (movie_id, title, predicted_rating) tuples\n",
    "    \"\"\"\n",
    "    # If user not in our data, return empty list\n",
    "    if user_id not in ratings_matrix.index:\n",
    "        return []\n",
    "        \n",
    "    # Get movies the user hasn't rated\n",
    "    user_rated_movies = set(ratings_with_info[ratings_with_info['userId'] == user_id]['movieId'])\n",
    "    candidate_movies = [\n",
    "        movie_id for movie_id in top_rated_movies \n",
    "        if movie_id not in user_rated_movies\n",
    "    ]\n",
    "    \n",
    "    # Calculate predicted ratings\n",
    "    predictions = []\n",
    "    for movie_id in candidate_movies:\n",
    "        # Skip movies with too few ratings\n",
    "        if movie_ratings_count.get(movie_id, 0) < min_ratings:\n",
    "            continue\n",
    "            \n",
    "        predicted = predict_rating(user_id, movie_id)\n",
    "        if predicted is not None:\n",
    "            # Get movie title\n",
    "            title = movies_cleaned[movies_cleaned['movieId'] == movie_id]['title'].values\n",
    "            if len(title) > 0:\n",
    "                predictions.append((movie_id, title[0], predicted))\n",
    "    \n",
    "    # Sort by predicted rating (descending) and return top n\n",
    "    predictions.sort(key=lambda x: x[2], reverse=True)\n",
    "    return predictions[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Recommendation System\n",
    "\n",
    "Let's test our recommendation system with a few users to see what kind of recommendations it produces. This gives us a qualitative sense of how well our system is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our recommendation system with a few users\n",
    "test_users = ratings_with_info['userId'].value_counts().head(3).index.tolist()\n",
    "\n",
    "for user_id in test_users:\n",
    "    print(f\"\\n===== Recommendations for User {user_id} =====\\n\")\n",
    "    \n",
    "    # Get the user's highest rated movies\n",
    "    user_ratings = ratings_with_info[ratings_with_info['userId'] == user_id]\n",
    "    top_rated = user_ratings.sort_values('rating', ascending=False).head(5)\n",
    "    \n",
    "    print(\"User's top rated movies:\")\n",
    "    for _, row in top_rated.iterrows():\n",
    "        movie_id = row['movieId']\n",
    "        title = movies_cleaned[movies_cleaned['movieId'] == movie_id]['title'].values\n",
    "        title = title[0] if len(title) > 0 else f\"Movie {movie_id}\"\n",
    "        print(f\"  - {title} (rating: {row['rating']})\")\n",
    "        \n",
    "    # Generate recommendations\n",
    "    print(\"\\nRecommended movies:\")\n",
    "    recommendations = recommend_movies(user_id, n=5)\n",
    "    \n",
    "    if recommendations:\n",
    "        for movie_id, title, predicted_rating in recommendations:\n",
    "            print(f\"  - {title} (predicted rating: {predicted_rating:.2f})\")\n",
    "    else:\n",
    "        print(\"  No recommendations could be generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Evaluation\n",
    "\n",
    "Beyond qualitative assessment, we need objective metrics to evaluate our recommendation system. We'll use leave-one-out cross-validation to measure how accurately our system can predict known ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our recommendation system using leave-one-out cross-validation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# Select a random sample of user-movie interactions for evaluation\n",
    "np.random.seed(42)\n",
    "sample_size = 10000  # Adjust based on your computational resources\n",
    "all_interactions = ratings_with_info[['userId', 'movieId', 'rating']].values\n",
    "sample_indices = np.random.choice(len(all_interactions), sample_size, replace=False)\n",
    "test_interactions = all_interactions[sample_indices]\n",
    "\n",
    "# Predict ratings for each interaction and compare with actual rating\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "for i, (user_id, movie_id, actual_rating) in enumerate(test_interactions):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Progress: {i}/{len(test_interactions)}\")\n",
    "        \n",
    "    predicted_rating = predict_rating(user_id, movie_id)\n",
    "    \n",
    "    if predicted_rating is not None:\n",
    "        predictions.append(predicted_rating)\n",
    "        actuals.append(actual_rating)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def calculate_metrics(predictions, actuals, threshold=4.0):\n",
    "    \"\"\"Calculate all evaluation metrics for the given predictions and actual values\"\"\"\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = math.sqrt(mean_squared_error(actuals, predictions))\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    true_positives = sum(1 for p, a in zip(predictions, actuals) \n",
    "                       if p >= threshold and a >= threshold)\n",
    "    false_positives = sum(1 for p, a in zip(predictions, actuals) \n",
    "                        if p >= threshold and a < threshold)\n",
    "    false_negatives = sum(1 for p, a in zip(predictions, actuals) \n",
    "                        if p < threshold and a >= threshold)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'true_positives': true_positives,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }\n",
    "\n",
    "if len(predictions) > 0:\n",
    "    # Calculate metrics at different thresholds\n",
    "    overall_mae = None\n",
    "    overall_rmse = None\n",
    "    \n",
    "    for threshold in [3.5, 4.0, 4.5]:\n",
    "        metrics = calculate_metrics(predictions, actuals, threshold)\n",
    "        \n",
    "        # Store overall metrics the first time\n",
    "        if threshold == 3.5:\n",
    "            overall_mae = metrics['mae']\n",
    "            overall_rmse = metrics['rmse']\n",
    "        \n",
    "        print(f\"\\nMetrics at rating threshold {threshold}:\")\n",
    "        print(f\"True Positives: {metrics['true_positives']}\")\n",
    "        print(f\"False Positives: {metrics['false_positives']}\")\n",
    "        print(f\"False Negatives: {metrics['false_negatives']}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nNumber of valid predictions: {len(predictions)}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {overall_mae:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {overall_rmse:.4f}\")\n",
    "else:\n",
    "    print(\"No valid predictions were made for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting the Item Similarity Matrix\n",
    "\n",
    "We save our computed similarity matrix to disk to avoid recalculating it in future sessions. This is an important optimization for real-world recommendation systems where similarity computations can be very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the similarity matrix for future use\n",
    "import pickle\n",
    "\n",
    "# Save the item similarity dictionary\n",
    "with open('../movies_data/item_similarity_3000.pkl', 'wb') as f:\n",
    "    pickle.dump(item_similarity, f)\n",
    "\n",
    "print(\"Item similarity matrix saved to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "To optimize our recommendation system, we need to tune several key hyperparameters that significantly impact performance. Finding the right values for these parameters can substantially improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Number of Neighbors (k)\n",
    "\n",
    "The number of similar items to consider when making predictions is a critical parameter. Too few neighbors might not capture enough information, while too many might introduce noise. We'll systematically test different values to find the optimal balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tune the number of neighbors (k) for item-based CF\n",
    "# We'll use a subset of our test data for efficiency\n",
    "test_subset = test_interactions[:3000] \n",
    "\n",
    "# Test different k values\n",
    "k_values = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "results = []\n",
    "threshold = 3.5  # We'll use a single threshold for hyperparameter tuning\n",
    "\n",
    "print(\"Testing different k values:\")\n",
    "for k in k_values:\n",
    "    print(f\"Testing with k={k}\")\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for user_id, movie_id, actual_rating in test_subset:\n",
    "        # Modify the predict_rating function to use the current k value\n",
    "        predicted = predict_rating(user_id, movie_id, k=k)\n",
    "        \n",
    "        if predicted is not None:\n",
    "            predictions.append(predicted)\n",
    "            actuals.append(actual_rating)\n",
    "    \n",
    "    if predictions:\n",
    "        metrics = calculate_metrics(predictions, actuals, threshold)\n",
    "        results.append((k, metrics['mae'], metrics['rmse'], \n",
    "                       metrics['precision'], metrics['recall'], \n",
    "                       metrics['f1_score'], len(predictions)))\n",
    "        print(f\"  MAE={metrics['mae']:.4f}, RMSE={metrics['rmse']:.4f}, \"\n",
    "              f\"Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, \"\n",
    "              f\"F1={metrics['f1_score']:.4f}, Count={len(predictions)}\")\n",
    "\n",
    "# Display results table\n",
    "print(\"\\nHyperparameter tuning results:\")\n",
    "print(\"k\\tMAE\\tRMSE\\tPrec.\\tRecall\\tF1\\tPred.\")\n",
    "for k, mae, rmse, prec, rec, f1, count in results:\n",
    "    print(f\"{k}\\t{mae:.4f}\\t{rmse:.4f}\\t{prec:.4f}\\t{rec:.4f}\\t{f1:.4f}\\t{count}\")\n",
    "\n",
    "# Find best k value based on F1 score and RMSE\n",
    "best_k_f1 = max(results, key=lambda x: x[5])[0]\n",
    "best_k_rmse = min(results, key=lambda x: x[2])[0]\n",
    "print(f\"\\nBest k value based on RMSE: {best_k_rmse}\")\n",
    "print(f\"Best k value based on F1 score: {best_k_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Aware Recommendations\n",
    "\n",
    "In many recommendation scenarios, newer items are more relevant than older ones. For movie recommendations, recent releases might be more interesting to users than older films. We'll enhance our recommendation system by incorporating release year information to prioritize newer movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Release Year from Movie Metadata\n",
    "\n",
    "First, we need to extract the release year from the movie data. The movies_metadata.csv file contains release date information that we can parse to get the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original movies metadata to access release dates\n",
    "original_movies = pd.read_csv('../movies_data/movies_metadata.csv', low_memory=False)\n",
    "\n",
    "# Display the columns related to release date\n",
    "date_columns = [col for col in original_movies.columns if 'date' in col.lower() or 'year' in col.lower()]\n",
    "print(f\"Date-related columns: {date_columns}\")\n",
    "print(original_movies[date_columns].head())\n",
    "\n",
    "# Extract release year from release_date\n",
    "def extract_year(date_str):\n",
    "    \"\"\"Extract the year from a date string in format YYYY-MM-DD\"\"\"\n",
    "    try:\n",
    "        if pd.isna(date_str) or date_str == '':\n",
    "            return None\n",
    "        # Try to extract year from YYYY-MM-DD format\n",
    "        year = str(date_str).split('-')[0]\n",
    "        # Check if it's a valid 4-digit year\n",
    "        if year.isdigit() and len(year) == 4 and 1900 <= int(year) <= 2023:\n",
    "            return int(year)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Add release year to our cleaned movies dataset\n",
    "# First create a mapping from movieId to release year\n",
    "id_to_year = {}\n",
    "for _, row in original_movies.iterrows():\n",
    "    try:\n",
    "        movie_id = int(float(row['id']))\n",
    "        year = extract_year(row.get('release_date', None))\n",
    "        if year is not None:\n",
    "            id_to_year[movie_id] = year\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Add release year to movies_cleaned\n",
    "movies_cleaned['release_year'] = movies_cleaned['movieId'].map(id_to_year)\n",
    "\n",
    "# Fill missing years with the median year\n",
    "median_year = movies_cleaned['release_year'].median()\n",
    "movies_cleaned['release_year'] = movies_cleaned['release_year'].fillna(median_year).astype(int)\n",
    "\n",
    "# Display distribution of movie release years\n",
    "print(\"\\nMovie release year distribution:\")\n",
    "year_counts = movies_cleaned['release_year'].value_counts().sort_index()\n",
    "print(f\"Earliest year: {year_counts.index.min()}, Latest year: {year_counts.index.max()}\")\n",
    "print(f\"Most common year: {movies_cleaned['release_year'].value_counts().idxmax()} with {movies_cleaned['release_year'].value_counts().max()} movies\")\n",
    "\n",
    "# Visualize the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(movies_cleaned['release_year'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Movie Release Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Time Bias in Recommendations\n",
    "\n",
    "Now we'll implement a time bias function that gives higher preference to newer movies. This bias will adjust the predicted ratings based on the movie's release year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate time bias\n",
    "def calculate_time_bias(release_year, current_year=2025, max_age=50, bias_strength=0.5):\n",
    "    \"\"\"Calculate a bias factor based on movie age.\n",
    "    \n",
    "    Args:\n",
    "        release_year: The year the movie was released\n",
    "        current_year: Current year (default: 2023)\n",
    "        max_age: Age at which bias reaches maximum penalty (default: 50 years)\n",
    "        bias_strength: How strong the bias should be (0-1, default: 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        float: A bias factor between 0 and 1, where newer movies get values closer to 1\n",
    "    \"\"\"\n",
    "    # Calculate movie age\n",
    "    age = max(0, current_year - release_year)\n",
    "    \n",
    "    # Normalize age to 0-1 range, capped at max_age\n",
    "    normalized_age = min(1.0, age / max_age)\n",
    "    \n",
    "    # Calculate bias factor (1 for newest, decreasing for older)\n",
    "    # The bias_strength parameter controls how quickly the bias decreases\n",
    "    bias = 1.0 - (normalized_age * bias_strength)\n",
    "    \n",
    "    return bias\n",
    "\n",
    "# Test the bias function with some example years\n",
    "test_years = [2025, 2020, 2015, 2010, 2000, 1990, 1980, 1970, 1950]\n",
    "print(\"Time bias values for different release years:\")\n",
    "for year in test_years:\n",
    "    bias = calculate_time_bias(year)\n",
    "    print(f\"Year {year}: bias = {bias:.4f}\")\n",
    "\n",
    "# Visualize the time bias function\n",
    "years = range(1950, 2025)\n",
    "biases = [calculate_time_bias(year) for year in years]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, biases)\n",
    "plt.title('Time Bias by Release Year')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Bias Factor')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Time-Aware Recommendations\n",
    "\n",
    "Now let's update our recommendation function to incorporate the time bias. We'll create two variations:\n",
    "\n",
    "1. A version that applies the time bias as a post-processing step\n",
    "2. A version that integrates the time bias directly into the rating prediction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated recommendation function with time bias\n",
    "def recommend_movies_with_time_bias(user_id, n=10, min_ratings=5, bias_strength=0.5, post_process=True):\n",
    "    \"\"\"Generate movie recommendations with time bias for a user\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): User ID\n",
    "        n (int): Number of recommendations to generate\n",
    "        min_ratings (int): Minimum number of ratings a movie should have\n",
    "        bias_strength (float): Strength of the time bias (0-1)\n",
    "        post_process (bool): If True, apply time bias after rating prediction;\n",
    "                            If False, integrate into the prediction process\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (movie_id, title, predicted_rating, release_year) tuples\n",
    "    \"\"\"\n",
    "    # If user not in our data, return empty list\n",
    "    if user_id not in ratings_matrix.index:\n",
    "        return []\n",
    "        \n",
    "    # Get movies the user hasn't rated\n",
    "    user_rated_movies = set(ratings_with_info[ratings_with_info['userId'] == user_id]['movieId'])\n",
    "    candidate_movies = [\n",
    "        movie_id for movie_id in top_rated_movies \n",
    "        if movie_id not in user_rated_movies\n",
    "    ]\n",
    "    \n",
    "    # Calculate predicted ratings\n",
    "    predictions = []\n",
    "    for movie_id in candidate_movies:\n",
    "        # Skip movies with too few ratings\n",
    "        if movie_ratings_count.get(movie_id, 0) < min_ratings:\n",
    "            continue\n",
    "            \n",
    "        # Get basic prediction\n",
    "        predicted = predict_rating(user_id, movie_id)\n",
    "        \n",
    "        if predicted is not None:\n",
    "            # Get movie metadata\n",
    "            movie_info = movies_cleaned[movies_cleaned['movieId'] == movie_id]\n",
    "            if len(movie_info) > 0:\n",
    "                title = movie_info['title'].values[0]\n",
    "                release_year = movie_info['release_year'].values[0]\n",
    "                \n",
    "                if post_process:\n",
    "                    # Post-processing approach: Apply time bias to predicted rating\n",
    "                    time_bias = calculate_time_bias(release_year, bias_strength=bias_strength)\n",
    "                    # Adjust prediction using the bias\n",
    "                    # This formula blends the original rating with the time bias\n",
    "                    # as bias_strength increases, newer movies get higher boost\n",
    "                    adjusted_rating = predicted * (1 + (time_bias - 0.5) * bias_strength)\n",
    "                    # Ensure the rating stays within valid range\n",
    "                    adjusted_rating = min(max(adjusted_rating, 0.5), 5.0)\n",
    "                    \n",
    "                    predictions.append((movie_id, title, adjusted_rating, release_year))\n",
    "                else:\n",
    "                    # Just store the regular prediction for now; we'll modify the prediction function later\n",
    "                    predictions.append((movie_id, title, predicted, release_year))\n",
    "    \n",
    "    # Sort by predicted rating (descending) and return top n\n",
    "    predictions.sort(key=lambda x: x[2], reverse=True)\n",
    "    return predictions[:n]\n",
    "\n",
    "# Let's update predict_rating to incorporate time bias if needed\n",
    "def predict_rating_with_time(user_id, movie_id, k=10, bias_strength=0.5):\n",
    "    \"\"\"Predict a user's rating for a movie using item-based CF with time bias\n",
    "    \n",
    "    This version integrates time bias directly into the prediction process\n",
    "    \"\"\"\n",
    "    # First get the basic prediction\n",
    "    basic_prediction = predict_rating(user_id, movie_id, k)\n",
    "    \n",
    "    if basic_prediction is None:\n",
    "        return None\n",
    "    \n",
    "    # Get movie release year\n",
    "    movie_info = movies_cleaned[movies_cleaned['movieId'] == movie_id]\n",
    "    if len(movie_info) > 0:\n",
    "        release_year = movie_info['release_year'].values[0]\n",
    "        \n",
    "        # Calculate time bias\n",
    "        time_bias = calculate_time_bias(release_year, bias_strength=bias_strength)\n",
    "        \n",
    "        # Adjust prediction - boost newer movies, decrease older ones\n",
    "        adjusted_prediction = basic_prediction * (1 + (time_bias - 0.5) * bias_strength)\n",
    "        \n",
    "        # Ensure prediction stays in valid range\n",
    "        return min(max(adjusted_prediction, 0.5), 5.0)\n",
    "    \n",
    "    return basic_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Time-Aware Recommendations\n",
    "\n",
    "Let's test our time-aware recommendation system and compare it with the original version. We'll look at how the recommendations change when we increase the bias toward newer movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a test user\n",
    "test_user_id = test_users[0]  # Using the first test user from earlier\n",
    "\n",
    "print(f\"\\n===== Comparing Recommendations for User {test_user_id} =====\\n\")\n",
    "\n",
    "# Get recommendations without time bias\n",
    "print(\"Original recommendations (no time bias):\")\n",
    "regular_recs = recommend_movies(test_user_id, n=10)\n",
    "for i, (movie_id, title, predicted_rating) in enumerate(regular_recs, 1):\n",
    "    # Look up the release year\n",
    "    year = movies_cleaned[movies_cleaned['movieId'] == movie_id]['release_year'].values\n",
    "    year_str = str(int(year[0])) if len(year) > 0 else \"Unknown\"\n",
    "    print(f\"  {i}. {title} ({year_str}) - predicted rating: {predicted_rating:.2f}\")\n",
    "\n",
    "# Test with different bias strengths\n",
    "bias_levels = [0.3, 0.6, 0.9]\n",
    "\n",
    "for bias in bias_levels:\n",
    "    print(f\"\\nRecommendations with time bias (strength={bias}):\\n\")\n",
    "    time_biased_recs = recommend_movies_with_time_bias(\n",
    "        test_user_id, n=10, bias_strength=bias, post_process=True\n",
    "    )\n",
    "    \n",
    "    for i, (movie_id, title, predicted_rating, year) in enumerate(time_biased_recs, 1):\n",
    "        print(f\"  {i}. {title} ({year}) - predicted rating: {predicted_rating:.2f}\")\n",
    "\n",
    "# Let's analyze how the recommendations change\n",
    "print(\"\\n===== Recommendation Analysis =====\\n\")\n",
    "\n",
    "# Calculate average year of recommendations for each method\n",
    "avg_year_regular = np.mean([movies_cleaned[movies_cleaned['movieId'] == movie_id]['release_year'].values[0] \n",
    "                         for movie_id, _, _ in regular_recs])\n",
    "\n",
    "avg_years_biased = []\n",
    "for bias in bias_levels:\n",
    "    time_recs = recommend_movies_with_time_bias(test_user_id, n=10, bias_strength=bias)\n",
    "    avg_year = np.mean([year for _, _, _, year in time_recs])\n",
    "    avg_years_biased.append(avg_year)\n",
    "\n",
    "print(f\"Average release year without bias: {avg_year_regular:.1f}\")\n",
    "for i, bias in enumerate(bias_levels):\n",
    "    print(f\"Average release year with bias={bias}: {avg_years_biased[i]:.1f}\")\n",
    "    \n",
    "# Visualize the shift in recommendation years\n",
    "labels = ['No bias'] + [f'Bias={b}' for b in bias_levels]\n",
    "years = [avg_year_regular] + avg_years_biased\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, years, color='skyblue')\n",
    "plt.title('Average Movie Release Year in Recommendations')\n",
    "plt.ylabel('Average Year')\n",
    "plt.axhline(y=avg_year_regular, color='r', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Time-Aware Recommendations\n",
    "\n",
    "Let's evaluate our time-aware recommendation system to understand its impact on prediction accuracy. We'll use the same evaluation metrics as before, but now compare the original and time-biased versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the recommendation systems with time bias\n",
    "eval_sample_size = 3000\n",
    "np.random.seed(42)\n",
    "eval_indices = np.random.choice(len(all_interactions), eval_sample_size, replace=False)\n",
    "eval_interactions = all_interactions[eval_indices]\n",
    "\n",
    "def evaluate_recommendations(interactions, predict_func, name=\"\"):\n",
    "    \"\"\"Evaluate a recommendation prediction function\"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for i, (user_id, movie_id, actual_rating) in enumerate(interactions):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Progress: {i}/{len(interactions)}\")\n",
    "            \n",
    "        predicted_rating = predict_func(user_id, movie_id)\n",
    "        \n",
    "        if predicted_rating is not None:\n",
    "            predictions.append(predicted_rating)\n",
    "            actuals.append(actual_rating)\n",
    "    \n",
    "    if predictions:\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        rmse = math.sqrt(mean_squared_error(actuals, predictions))\n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "        print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "        print(f\"Number of valid predictions: {len(predictions)}\")\n",
    "        return {'name': name, 'mae': mae, 'rmse': rmse, 'count': len(predictions)}\n",
    "    else:\n",
    "        print(f\"No valid predictions for {name}\")\n",
    "        return None\n",
    "\n",
    "# Evaluate the original recommendation system\n",
    "print(\"\\nEvaluating original recommendation system...\")\n",
    "original_results = evaluate_recommendations(\n",
    "    eval_interactions,\n",
    "    lambda u, m: predict_rating(u, m, k=40),  # Using k=40 based on earlier tuning\n",
    "    \"Original\"\n",
    ")\n",
    "\n",
    "# Evaluate with different time bias strengths\n",
    "time_results = []\n",
    "for bias in [0.3, 0.6, 0.9]:\n",
    "    print(f\"\\nEvaluating time-biased recommendations (bias={bias})...\")\n",
    "    result = evaluate_recommendations(\n",
    "        eval_interactions,\n",
    "        lambda u, m: predict_rating_with_time(u, m, k=40, bias_strength=bias),\n",
    "        f\"Time-biased (bias={bias})\"\n",
    "    )\n",
    "    if result:\n",
    "        time_results.append(result)\n",
    "\n",
    "# Compare the results\n",
    "if original_results and time_results:\n",
    "    # Prepare data for plotting\n",
    "    methods = [original_results['name']] + [r['name'] for r in time_results]\n",
    "    mae_values = [original_results['mae']] + [r['mae'] for r in time_results]\n",
    "    rmse_values = [original_results['rmse']] + [r['rmse'] for r in time_results]\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # MAE subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(methods, mae_values, color='skyblue')\n",
    "    plt.title('Mean Absolute Error')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # RMSE subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(methods, rmse_values, color='lightgreen')\n",
    "    plt.title('Root Mean Squared Error')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Time-Aware Recommendations\n",
    "\n",
    "We've successfully enhanced our recommendation system by incorporating movie release years to bias recommendations toward newer movies. Here's what we learned:\n",
    "\n",
    "1. **Time bias implementation**: We created a flexible bias function that allows us to control how strongly we favor newer movies.\n",
    "\n",
    "2. **Recommendation changes**: As we increased the bias strength, our recommendations shifted toward more recent movies, which can help ensure users see more contemporary content.\n",
    "\n",
    "3. **Impact on accuracy**: Our evaluation showed how the time bias affects prediction accuracy. There's often a trade-off where stronger bias toward newer movies may slightly decrease overall prediction accuracy but potentially increase user satisfaction by recommending more recent content.\n",
    "\n",
    "4. **Tunable parameter**: The bias strength parameter gives us a way to control this trade-off, letting us balance accuracy with the desire to promote newer content.\n",
    "\n",
    "This time-awareness feature addresses a common limitation of traditional collaborative filtering systems, which tend to favor older, more-rated items. By incorporating release year information, our recommendation system becomes more dynamic and can better serve users interested in discovering recent content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Time Bias to Reduce Error\n",
    "\n",
    "We noticed that adding time bias increases our prediction error (MSE/RMSE). This is expected because we're deliberately shifting predictions to favor newer movies, which may not align with the historical ratings data. Let's explore ways to optimize our time bias approach to maintain reasonable accuracy while still promoting newer content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine our time bias approach to reduce error\n",
    "\n",
    "# Define an improved time bias function with more parameters to control the effect\n",
    "def calculate_adaptive_time_bias(release_year, current_year=2023, max_age=50, \n",
    "                               base_bias=0.3, rating_offset=0.0, apply_curve=True):\n",
    "    \"\"\"Calculate a smarter bias factor based on movie age.\n",
    "    \n",
    "    Args:\n",
    "        release_year: The year the movie was released\n",
    "        current_year: Current year (default: 2023)\n",
    "        max_age: Age at which bias reaches maximum penalty (default: 50 years)\n",
    "        base_bias: Maximum bias effect (0-1, default: 0.3)\n",
    "        rating_offset: Instead of multiplying, add this offset to newer movies (default: 0)\n",
    "        apply_curve: Whether to apply a nonlinear curve to the bias (default: True)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (bias_factor, additive_offset)\n",
    "    \"\"\"\n",
    "    # Calculate movie age\n",
    "    age = max(0, current_year - release_year)\n",
    "    \n",
    "    # Normalize age to 0-1 range, capped at max_age\n",
    "    normalized_age = min(1.0, age / max_age)\n",
    "    \n",
    "    # Apply non-linear curve if requested (reduces the effect for middle-aged movies)\n",
    "    if apply_curve:\n",
    "        # Apply a sigmoid-like curve that reduces the penalty for movies of medium age\n",
    "        # and concentrates the effect on very old and very new movies\n",
    "        import numpy as np\n",
    "        normalized_age = 1 / (1 + np.exp(-10 * (normalized_age - 0.5)))\n",
    "    \n",
    "    # Calculate multiplicative bias factor (1 for newest, decreasing for older)\n",
    "    bias_factor = 1.0 - (normalized_age * base_bias)\n",
    "    \n",
    "    # Calculate additive offset (positive for new movies, zero for old ones)\n",
    "    # This helps preserve the relative scale of ratings\n",
    "    additive_offset = rating_offset * (1.0 - normalized_age)\n",
    "    \n",
    "    return bias_factor, additive_offset\n",
    "\n",
    "# Updated prediction function with improved bias handling\n",
    "def predict_rating_with_adaptive_bias(user_id, movie_id, k=40, \n",
    "                                    base_bias=0.2, rating_offset=0.1, apply_curve=True):\n",
    "    \"\"\"Predict a user's rating using a more sophisticated time bias approach\"\"\"\n",
    "    # First get the basic prediction\n",
    "    basic_prediction = predict_rating(user_id, movie_id, k)\n",
    "    \n",
    "    if basic_prediction is None:\n",
    "        return None\n",
    "    \n",
    "    # Get movie release year\n",
    "    movie_info = movies_cleaned[movies_cleaned['movieId'] == movie_id]\n",
    "    if len(movie_info) > 0:\n",
    "        release_year = movie_info['release_year'].values[0]\n",
    "        \n",
    "        # Calculate time bias using the improved function\n",
    "        bias_factor, additive_offset = calculate_adaptive_time_bias(\n",
    "            release_year, base_bias=base_bias, rating_offset=rating_offset, apply_curve=apply_curve\n",
    "        )\n",
    "        \n",
    "        # Apply a gentler adjustment that combines multiplicative and additive effects\n",
    "        # The multiplicative factor helps preserve the user's rating scale\n",
    "        # The additive offset helps boost newer movies without extreme distortion\n",
    "        adjusted_prediction = basic_prediction * bias_factor + additive_offset\n",
    "        \n",
    "        # Ensure prediction stays in valid range\n",
    "        return min(max(adjusted_prediction, 0.5), 5.0)\n",
    "    \n",
    "    return basic_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating optimized time-biased recommendations...\")\n",
    "\n",
    "# Try different parameter combinations\n",
    "parameter_sets = [\n",
    "    {'base_bias': 0.1, 'rating_offset': 0.0, 'apply_curve': False, 'name': 'Light bias (0.1), no offset'},\n",
    "    {'base_bias': 0.2, 'rating_offset': 0.1, 'apply_curve': True, 'name': 'Medium bias (0.2) with offset (0.1)'},\n",
    "    {'base_bias': 0.0, 'rating_offset': 0.2, 'apply_curve': False, 'name': 'No factor bias, offset only (0.2)'},\n",
    "    {'base_bias': 0.1, 'rating_offset': 0.1, 'apply_curve': True, 'name': 'Balanced approach'}\n",
    "]\n",
    "\n",
    "adaptive_results = []\n",
    "for params in parameter_sets:\n",
    "    print(f\"\\nEvaluating {params['name']}...\")\n",
    "    \n",
    "    # Create a prediction function with these parameters\n",
    "    def predict_with_params(u, m):\n",
    "        return predict_rating_with_adaptive_bias(\n",
    "            u, m, k=40, \n",
    "            base_bias=params['base_bias'],\n",
    "            rating_offset=params['rating_offset'],\n",
    "            apply_curve=params['apply_curve']\n",
    "        )\n",
    "    \n",
    "    # Evaluate\n",
    "    result = evaluate_recommendations(\n",
    "        eval_interactions[:3000],\n",
    "        predict_with_params,\n",
    "        params['name']\n",
    "    )\n",
    "    if result:\n",
    "        adaptive_results.append(result)\n",
    "\n",
    "# Compare with original prediction (no bias)\n",
    "original_subset_result = evaluate_recommendations(\n",
    "    eval_interactions[:1000],\n",
    "    lambda u, m: predict_rating(u, m, k=40),\n",
    "    \"Original (no bias)\"\n",
    ")\n",
    "\n",
    "# Plot results if we have them\n",
    "if adaptive_results and original_subset_result:\n",
    "    # Prepare data for plotting\n",
    "    all_results = [original_subset_result] + adaptive_results\n",
    "    methods = [r['name'] for r in all_results]\n",
    "    mae_values = [r['mae'] for r in all_results]\n",
    "    rmse_values = [r['rmse'] for r in all_results]\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # MAE subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(methods, mae_values)\n",
    "    plt.title('Mean Absolute Error')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.axhline(y=original_subset_result['mae'], color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Highlight the best approach\n",
    "    best_idx = mae_values.index(min(mae_values))\n",
    "    bars[best_idx].set_color('green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # RMSE subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.bar(methods, rmse_values)\n",
    "    plt.title('Root Mean Squared Error')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.axhline(y=original_subset_result['rmse'], color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Highlight the best approach\n",
    "    best_idx = rmse_values.index(min(rmse_values))\n",
    "    bars[best_idx].set_color('green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Recommendations with Adaptive Time Bias\n",
    "\n",
    "Now we'll use our refined time bias approach to generate recommendations. Let's use the optimal parameters we found for a balance between accuracy and recency preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate recommendations using the adaptive time bias\n",
    "def recommend_with_adaptive_bias(user_id, n=10, min_ratings=5, \n",
    "                              base_bias=0.1, rating_offset=0.1, apply_curve=True):\n",
    "    \"\"\"Generate movie recommendations for a user using adaptive time bias\"\"\"\n",
    "    # If user not in our data, return empty list\n",
    "    if user_id not in ratings_matrix.index:\n",
    "        return []\n",
    "        \n",
    "    # Get movies the user hasn't rated\n",
    "    user_rated_movies = set(ratings_with_info[ratings_with_info['userId'] == user_id]['movieId'])\n",
    "    candidate_movies = [\n",
    "        movie_id for movie_id in top_rated_movies \n",
    "        if movie_id not in user_rated_movies\n",
    "    ]\n",
    "    \n",
    "    # Calculate predicted ratings\n",
    "    predictions = []\n",
    "    for movie_id in candidate_movies:\n",
    "        # Skip movies with too few ratings\n",
    "        if movie_ratings_count.get(movie_id, 0) < min_ratings:\n",
    "            continue\n",
    "            \n",
    "        # Get prediction using adaptive bias\n",
    "        predicted = predict_rating_with_adaptive_bias(\n",
    "            user_id, movie_id, k=40,\n",
    "            base_bias=base_bias, \n",
    "            rating_offset=rating_offset,\n",
    "            apply_curve=apply_curve\n",
    "        )\n",
    "        \n",
    "        if predicted is not None:\n",
    "            # Get movie metadata\n",
    "            movie_info = movies_cleaned[movies_cleaned['movieId'] == movie_id]\n",
    "            if len(movie_info) > 0:\n",
    "                title = movie_info['title'].values[0]\n",
    "                release_year = movie_info['release_year'].values[0]\n",
    "                predictions.append((movie_id, title, predicted, release_year))\n",
    "    \n",
    "    # Sort by predicted rating (descending) and return top n\n",
    "    predictions.sort(key=lambda x: x[2], reverse=True)\n",
    "    return predictions[:n]\n",
    "\n",
    "# Test our refined recommendation system\n",
    "test_user = test_users[0]  # Using our first test user again\n",
    "\n",
    "print(f\"\\n===== Recommendations with Adaptive Time Bias for User {test_user} =====\\n\")\n",
    "\n",
    "# Original recommendations\n",
    "print(\"Original recommendations (no time bias):\")\n",
    "original_recs = recommend_movies(test_user, n=10)\n",
    "for i, (movie_id, title, predicted) in enumerate(original_recs, 1):\n",
    "    year = movies_cleaned[movies_cleaned['movieId'] == movie_id]['release_year'].values[0] \\\n",
    "           if movie_id in movies_cleaned['movieId'].values else \"Unknown\"\n",
    "    print(f\"  {i}. {title} ({year}) - predicted: {predicted:.2f}\")\n",
    "\n",
    "# Get recommendations with our balanced bias approach\n",
    "print(\"\\nRecommendations with adaptive time bias:\")\n",
    "adaptive_recs = recommend_with_adaptive_bias(\n",
    "    test_user, n=10, base_bias=0.1, rating_offset=0.1, apply_curve=True\n",
    ")\n",
    "\n",
    "for i, (movie_id, title, predicted, year) in enumerate(adaptive_recs, 1):\n",
    "    print(f\"  {i}. {title} ({year}) - predicted: {predicted:.2f}\")\n",
    "\n",
    "# Calculate and display average release years\n",
    "avg_year_original = np.mean([\n",
    "    movies_cleaned[movies_cleaned['movieId'] == movie_id]['release_year'].values[0]\n",
    "    for movie_id, _, _ in original_recs\n",
    "    if movie_id in movies_cleaned['movieId'].values\n",
    "])\n",
    "\n",
    "avg_year_adaptive = np.mean([year for _, _, _, year in adaptive_recs])\n",
    "\n",
    "print(f\"\\nAverage release year (original): {avg_year_original:.1f}\")\n",
    "print(f\"Average release year (adaptive): {avg_year_adaptive:.1f}\")\n",
    "print(f\"Year difference: +{avg_year_adaptive - avg_year_original:.1f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusions on Time Bias Optimization\n",
    "\n",
    "We've successfully refined our time bias approach to better balance accuracy with the preference for newer content. Here are the key findings:\n",
    "\n",
    "1. **Impact of Time Bias**: Using a naive time bias approach significantly increased prediction error (MSE/RMSE), confirming that artificially boosting newer movies can reduce accuracy when measured against historical ratings.\n",
    "\n",
    "2. **Refinement Strategy**: By implementing an adaptive bias mechanism with:\n",
    "   - A milder multiplicative factor (base_bias)\n",
    "   - A small additive component (rating_offset)\n",
    "   - A non-linear curve to reduce the penalty for mid-age movies\n",
    "   We were able to reduce the error increase while still prioritizing newer content.\n",
    "\n",
    "3. **Optimal Parameters**: The best balance between accuracy and recency preference was achieved with a light multiplicative bias (0.1) combined with a small additive offset (0.1) and a non-linear application curve.\n",
    "\n",
    "4. **Trade-off Understanding**: There will always be a fundamental trade-off between purely predictive accuracy and recommending newer content. The optimal approach depends on business goals - whether you value accurate rating predictions more heavily than promoting recent content.\n",
    "\n",
    "5. **Practical Implementation**: In a production recommendation system, you might:\n",
    "   - Use different bias parameters for different user segments\n",
    "   - Dynamically adjust bias based on user behavior\n",
    "   - A/B test different settings to optimize engagement metrics beyond just prediction accuracy\n",
    "\n",
    "6. **Metrics Beyond RMSE**: While RMSE is useful for comparing models, real-world recommendation systems might be better evaluated by engagement metrics (clicks, watch time, purchases) rather than just rating prediction accuracy.\n",
    "\n",
    "By understanding and carefully tuning the time bias parameters, we've created a more balanced recommendation system that can prioritize newer content without excessively sacrificing accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
